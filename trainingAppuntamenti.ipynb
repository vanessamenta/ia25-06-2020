{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonna:No-show ['No' 'Yes']\n",
      "Colonna:PatientId [1.16723945e+11 2.37549850e+13 9.43571216e+10 ... 5.53613414e+14\n",
      " 8.87375234e+14 1.24658919e+13]\n",
      "Colonna:AppointmentID [5778236 5739813 5683899 ... 5622058 5717386 5723664]\n",
      "Colonna:Gender ['M' 'F']\n",
      "Colonna:ScheduledDay ['2016-06-06T15:14:21Z' '2016-05-25T14:10:29Z' '2016-05-11T08:00:20Z' ...\n",
      " '2016-05-13T15:43:41Z' '2016-04-26T11:16:09Z' '2016-05-20T08:29:12Z']\n",
      "Colonna:AppointmentDay ['2016-06-08T00:00:00Z' '2016-05-30T00:00:00Z' '2016-05-11T00:00:00Z'\n",
      " '2016-05-16T00:00:00Z' '2016-05-17T00:00:00Z' '2016-05-06T00:00:00Z'\n",
      " '2016-06-03T00:00:00Z' '2016-05-12T00:00:00Z' '2016-05-25T00:00:00Z'\n",
      " '2016-05-02T00:00:00Z' '2016-05-09T00:00:00Z' '2016-05-31T00:00:00Z'\n",
      " '2016-05-18T00:00:00Z' '2016-05-20T00:00:00Z' '2016-06-02T00:00:00Z'\n",
      " '2016-06-01T00:00:00Z' '2016-05-05T00:00:00Z' '2016-05-13T00:00:00Z'\n",
      " '2016-05-04T00:00:00Z' '2016-05-03T00:00:00Z' '2016-06-07T00:00:00Z'\n",
      " '2016-05-19T00:00:00Z' '2016-05-10T00:00:00Z' '2016-04-29T00:00:00Z'\n",
      " '2016-05-24T00:00:00Z' '2016-06-06T00:00:00Z' '2016-05-14T00:00:00Z']\n",
      "Colonna:Age [  9  50  69  22   1   5  46  61  51  29  38  41   3  74  25  40  65   0\n",
      "  33  83  72  58  13  86   8  15  17  20  21  18  32  44  84   6  67  30\n",
      "  63  70  64  23  71  60  53  37  16  79  27  57   2  36  11  55  42  48\n",
      "  54  76  24  43  52  59  28  87  62  26  47  39  19  14  34  95  75  68\n",
      "  56  45  12  80  49  10  35   4   7  31  73  82  78  81  66  85  88  77\n",
      "  93  94  91  89  90  92 102  96 100  98  97]\n",
      "Colonna:Neighbourhood ['INHANGUETÁ' 'ANDORINHAS' 'JARDIM CAMBURI' 'FORTE SÃO JOÃO' 'REDENÇÃO'\n",
      " 'MARUÍPE' 'REPÚBLICA' 'CENTRO' 'BOA VISTA' 'JESUS DE NAZARETH' 'DA PENHA'\n",
      " 'NOVA PALESTINA' 'SANTA LUÍZA' 'JARDIM DA PENHA' 'RESISTÊNCIA'\n",
      " 'SANTA MARTHA' 'BELA VISTA' 'MARIA ORTIZ' 'SANTO ANTÔNIO' 'JABOUR'\n",
      " 'TABUAZEIRO' 'ILHA DAS CAIEIRAS' 'SÃO CRISTÓVÃO' 'ILHA DE SANTA MARIA'\n",
      " 'ROMÃO' 'SÃO PEDRO' 'ITARARÉ' 'BONFIM' 'SÃO JOSÉ' 'ESTRELINHA'\n",
      " 'CONSOLAÇÃO' 'PIEDADE' 'SANTO ANDRÉ' 'ILHA DO PRÍNCIPE' 'SANTA LÚCIA'\n",
      " 'SÃO BENEDITO' 'NAZARETH' 'DO QUADRO' 'CRUZAMENTO' 'FONTE GRANDE'\n",
      " 'BARRO VERMELHO' 'ARIOVALDO FAVALESSA' 'CARATOÍRA' 'JUCUTUQUARA'\n",
      " 'VILA RUBIM' 'GOIABEIRAS' 'PRAIA DO CANTO' 'GURIGICA' 'DO MOSCOSO'\n",
      " 'JOANA D´ARC' 'PRAIA DO SUÁ' 'SANTOS REIS' 'PARQUE MOSCOSO' 'DO CABRAL'\n",
      " 'MÁRIO CYPRESTE' 'UNIVERSITÁRIO' 'SANTA TEREZA' 'GRANDE VITÓRIA'\n",
      " 'SANTA CECÍLIA' 'DE LOURDES' 'MONTE BELO' 'FRADINHOS' 'SANTA CLARA'\n",
      " 'SANTOS DUMONT' 'COMDUSA' 'BENTO FERREIRA' 'HORTO' 'MATA DA PRAIA'\n",
      " 'CONQUISTA' 'SANTA HELENA' 'SOLON BORGES' 'MORADA DE CAMBURI'\n",
      " 'SEGURANÇA DO LAR' 'ILHA DO BOI' 'ANTÔNIO HONÓRIO' 'ENSEADA DO SUÁ'\n",
      " 'ILHA DO FRADE' 'PONTAL DE CAMBURI' 'AEROPORTO'\n",
      " 'ILHAS OCEÂNICAS DE TRINDADE']\n",
      "Colonna:Scholarship [0 1]\n",
      "Colonna:Hipertension [0 1]\n",
      "Colonna:Diabetes [0 1]\n",
      "Colonna:Alcoholism [0 1]\n",
      "Colonna:Handcap [0 1 2 4 3]\n",
      "Colonna:SMS_received [0 1]\n"
     ]
    }
   ],
   "source": [
    "#vedo per ogni colonna quali sono i valori unici\n",
    "#non ci sono valori nan\n",
    "#noto che 00.00 è l'ora per ogni AppointmentDay\n",
    "for el in train.columns:\n",
    "    print(\"Colonna:\"+el+\"\",train[el].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22106 entries, 0 to 22105\n",
      "Data columns (total 14 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   No-show         22106 non-null  object \n",
      " 1   PatientId       22106 non-null  float64\n",
      " 2   AppointmentID   22106 non-null  int64  \n",
      " 3   Gender          22106 non-null  object \n",
      " 4   ScheduledDay    22106 non-null  object \n",
      " 5   AppointmentDay  22106 non-null  object \n",
      " 6   Age             22106 non-null  int64  \n",
      " 7   Neighbourhood   22106 non-null  object \n",
      " 8   Scholarship     22106 non-null  int64  \n",
      " 9   Hipertension    22106 non-null  int64  \n",
      " 10  Diabetes        22106 non-null  int64  \n",
      " 11  Alcoholism      22106 non-null  int64  \n",
      " 12  Handcap         22106 non-null  int64  \n",
      " 13  SMS_received    22106 non-null  int64  \n",
      "dtypes: float64(1), int64(8), object(5)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#non ci sono valori nulli\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dal giorno in cui è stato fissato l'appuntamento e il giorno effettivo della visita calcolo daysToAppointment\n",
    "#daysToAppointment indica i giorni di attesa \n",
    "#trasformo le date da stringhe in datetime e poi faccio la differenza\n",
    "#a questo punto le colonne ScheduledDay e AppointmentDay non serviranno più all'analisi\n",
    "train.ScheduledDay = train.ScheduledDay.apply(np.datetime64)\n",
    "train.AppointmentDay = train.AppointmentDay.apply(np.datetime64)\n",
    "test.ScheduledDay = test.ScheduledDay.apply(np.datetime64)\n",
    "test.AppointmentDay = test.AppointmentDay.apply(np.datetime64)\n",
    "\n",
    "daysToAppointment = train.AppointmentDay - train.ScheduledDay\n",
    "daysToAppointment = daysToAppointment.apply(lambda x: x.total_seconds() / (3600 * 24))\n",
    "train['daysToAppointment'] = daysToAppointment\n",
    "\n",
    "daysToAppointment = test.AppointmentDay - test.ScheduledDay\n",
    "daysToAppointment = daysToAppointment.apply(lambda x: x.total_seconds() / (3600 * 24))\n",
    "test['daysToAppointment'] = daysToAppointment\n",
    "\n",
    "\n",
    "train['daysToAppointment']= train['daysToAppointment'].astype('int64')\n",
    "test['daysToAppointment']= test['daysToAppointment'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['No-show', 'PatientId', 'AppointmentID', 'Gender', 'ScheduledDay',\n",
       "       'AppointmentDay', 'Age', 'Neighbourhood', 'Scholarship', 'Hipertension',\n",
       "       'Diabetes', 'Alcoholism', 'Handcap', 'SMS_received',\n",
       "       'daysToAppointment'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         4\n",
       "2         0\n",
       "3         3\n",
       "4         0\n",
       "         ..\n",
       "22101    15\n",
       "22102     6\n",
       "22103     7\n",
       "22104     0\n",
       "22105     0\n",
       "Name: daysToAppointment, Length: 22106, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.daysToAppointment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimuovo le righe con degli eventuali futuri valori nulli\n",
    "#rimuovo le colonne non utili ai fini dell'analisi: AppointmentID, PatientId e Neighbourhood, 'AppointmentDay', 'ScheduledDay'\n",
    "#separo il target dalle predizioni sia per il validation set sia per il training set\n",
    "train.dropna(axis=0, subset=['No-show', 'PatientId', 'AppointmentID', 'Neighbourhood',\n",
    "                             'AppointmentDay', 'ScheduledDay'], inplace=True)\n",
    "y_train = train['No-show']\n",
    "X_train = train.drop(['No-show', 'PatientId', 'AppointmentID',  'Neighbourhood',\n",
    "                     'AppointmentDay', 'ScheduledDay'], axis=1).copy()\n",
    "\n",
    "test.dropna(axis=0, subset=['No-show', 'PatientId', 'AppointmentID', 'Neighbourhood',\n",
    "                           'AppointmentDay', 'ScheduledDay'], inplace=True)\n",
    "y_valid = test['No-show']\n",
    "X_valid = test.drop(['No-show', 'PatientId', 'AppointmentID', 'Neighbourhood',\n",
    "                    'AppointmentDay', 'ScheduledDay'], axis=1).copy()\n",
    "\n",
    "#seleziono le colonne categoriche\n",
    "cat_cols = [cname for cname in X_train.columns if \n",
    "                    X_train[cname].dtype == \"object\"]\n",
    "\n",
    "# Seleziono le colonne numeriche\n",
    "num_cols = [cname for cname in X_train.columns if \n",
    "                X_train[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline per combinare in sequenza le diverse operazioni sui dati\n",
    "#i valori mancanti vengono sostituiti con la media grazie all'imputazione\n",
    "#le variabili categoriche vengono trasfprmate con il OneHot-encoder, il quale crea nuove colonne che indicano \n",
    "#presenza (o l'assenza) per ogni valore possibile presente nei dati\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median', missing_values=np.nan)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent', missing_values=np.nan)),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "]) \n",
    "\n",
    "# preprocessamento dei dati a seconda del loro tipo\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_cols),\n",
    "        ('cat', cat_transformer, cat_cols),\n",
    "    ])\n",
    "\n",
    "# mettendo il criterio entropia il root node  partiziona i dati usando la feature che fornisce il valore\n",
    "#informazionale più alto\n",
    "model = DecisionTreeClassifier(criterion='entropy', random_state=0, max_depth=5, splitter='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#riduco la dimensionalità con la feature selection \n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('skb', SelectKBest(f_classif, k = 10)),\n",
    "                              ('model', model)\n",
    "                             ])\n",
    "\n",
    "# alleno il modello\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predizioni\n",
    "preds = my_pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796335670662746"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model=accuracy_score(preds, y_valid)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
